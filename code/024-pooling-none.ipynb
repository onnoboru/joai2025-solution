{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle 実行！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-01T01:22:35.721Z",
     "iopub.execute_input": "2025-05-01T01:21:43.819610Z",
     "iopub.status.busy": "2025-05-01T01:21:43.819456Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightning\n",
      "  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2025.3.2)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (0.14.3)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (24.2)\n",
      "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (1.7.1)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.13.1)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.16)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.19.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\n",
      "Downloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, lightning\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n"
     ]
    }
   ],
   "source": [
    "!pip install lightning\n",
    "!pip uninstall torch_xla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-01T01:22:35.722Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/usr/local/cuda\"\n",
    "# または環境変数を完全に無効化\n",
    "os.environ[\"PJRT_DEVICE\"] = \"CUDA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-01T01:22:35.722Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "import wandb\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb_key\")\n",
    "wandb.login(key=secret_value_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-01T01:22:35.722Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/usr/local/cuda\"\n",
    "# または環境変数を完全に無効化\n",
    "os.environ[\"PJRT_DEVICE\"] = \"CUDA\"\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import copy\n",
    "import random\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import seed_everything as pl_seed_everything\n",
    "from lightning.pytorch.loggers import WandbLogger, TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "import transformers\n",
    "\n",
    "import wandb\n",
    "\n",
    "from albumentations.core.transforms_interface import DualTransform\n",
    "from albumentations.augmentations import functional as AF\n",
    "\n",
    "\n",
    "class GridMask(DualTransform):\n",
    "    \"\"\"GridMask augmentation for image classification and object detection.\n",
    "\n",
    "    Citation : This code is copied from and based on the original code from https://www.kaggle.com/code/haqishen/gridmask\n",
    "    Thanks to the author.\n",
    "    \n",
    "    Args:\n",
    "        num_grid (int): number of grid in a row or column.\n",
    "        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\n",
    "        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\n",
    "            an angle is picked from (-rotate, rotate). Default: (-90, 90)\n",
    "        mode (int):\n",
    "            0 - cropout a quarter of the square of each grid (left top)\n",
    "            1 - reserve a quarter of the square of each grid (left top)\n",
    "            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\n",
    "\n",
    "    Targets:\n",
    "        image, mask\n",
    "\n",
    "    Image types:\n",
    "        uint8, float32\n",
    "\n",
    "    Reference:\n",
    "    |  https://arxiv.org/abs/2001.04086\n",
    "    |  https://github.com/akuxcw/GridMask\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
    "        super(GridMask, self).__init__(always_apply, p)\n",
    "        if isinstance(num_grid, int):\n",
    "            num_grid = (num_grid, num_grid)\n",
    "        if isinstance(rotate, int):\n",
    "            rotate = (-rotate, rotate)\n",
    "        self.num_grid = num_grid\n",
    "        self.fill_value = fill_value\n",
    "        self.rotate = rotate\n",
    "        self.mode = mode\n",
    "        self.masks = None\n",
    "        self.rand_h_max = []\n",
    "        self.rand_w_max = []\n",
    "\n",
    "    def init_masks(self, height, width):\n",
    "        if self.masks is None:\n",
    "            self.masks = []\n",
    "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
    "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
    "                grid_h = height / n_g\n",
    "                grid_w = width / n_g\n",
    "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
    "                for i in range(n_g + 1):\n",
    "                    for j in range(n_g + 1):\n",
    "                        this_mask[\n",
    "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
    "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
    "                        ] = self.fill_value\n",
    "                        if self.mode == 2:\n",
    "                            this_mask[\n",
    "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
    "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
    "                            ] = self.fill_value\n",
    "                \n",
    "                if self.mode == 1:\n",
    "                    this_mask = 1 - this_mask\n",
    "\n",
    "                self.masks.append(this_mask)\n",
    "                self.rand_h_max.append(grid_h)\n",
    "                self.rand_w_max.append(grid_w)\n",
    "                \n",
    "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
    "        h, w = image.shape[:2]\n",
    "        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
    "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
    "        # 新しい配列を作成して返す\n",
    "        new_image = image.copy()  # 画像のコピーを作成\n",
    "        new_image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
    "        return new_image\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        img = params['image']\n",
    "        height, width = img.shape[:2]\n",
    "        self.init_masks(height, width)\n",
    "\n",
    "        mid = np.random.randint(len(self.masks))\n",
    "        mask = self.masks[mid]\n",
    "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
    "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
    "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
    "\n",
    "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
    "\n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('num_grid', 'fill_value', 'rotate', 'mode')\n",
    "\n",
    "\n",
    "# %%\n",
    "class CFG : \n",
    "    exp_name = \"024_pooling_none\"\n",
    "    random_seed = 42\n",
    "    \n",
    "    # model info\n",
    "    model = \"resnet50.a1h_in1k\"\n",
    "    use_custom_pooling = False\n",
    "    dropout_ratio = 0.3\n",
    "    \n",
    "    # train info\n",
    "    epochs = 100\n",
    "    batch_size = 64\n",
    "    learning_rate = 1e-3\n",
    "    num_workers = 8\n",
    "    num_classes = 4\n",
    "    device = \"cuda\"\n",
    "    criterion =  nn.BCEWithLogitsLoss\n",
    "    optimizer = optim.AdamW \n",
    "    scheduler = transformers.get_cosine_schedule_with_warmup\n",
    "    warmup_prop = 0.1\n",
    "    patience = 10\n",
    "    precision = \"16-mixed\" \n",
    "    do_tta = False\n",
    "    smoothing = 0.01\n",
    "    \n",
    "    # run info\n",
    "    debug_one_epoch = False\n",
    "    debug_one_fold = False\n",
    "    only_infer = False\n",
    "    do_wandb = True\n",
    "    \n",
    "    # data info\n",
    "    imput_img_size = 224\n",
    "    train_img_size = 224\n",
    "    # data_dir = \"/kaggle/input/joai-dataset\"\n",
    "    # output_dir = \"/kaggle/working/\"\n",
    "    data_dir = \"../dataset/\"\n",
    "    output_dir = \"../outputs/\"\n",
    "    fold = 5\n",
    "    \n",
    "config = CFG()\n",
    "\n",
    "# %%\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    pl_seed_everything(seed)\n",
    "    \n",
    "seed_everything(config.random_seed)\n",
    "\n",
    "# %%\n",
    "def class_to_dict(obj):\n",
    "    return {k: getattr(obj, k) for k in dir(obj) if not k.startswith(\"__\") and not callable(getattr(obj, k))}\n",
    "class_dict = class_to_dict(config)\n",
    "\n",
    "# %%\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(config.train_img_size, config.train_img_size),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(config.imput_img_size, config.imput_img_size),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# %%\n",
    "def add_degrees_celcius(df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add a column to the DataFrame indicating if the temperature is in Celsius.\n",
    "    \"\"\"\n",
    "    df[\"Caption\"] = df[\"Caption\"].astype(str) \n",
    "    df['is_degrees_celsius'] = df[\"Caption\"].str.contains(\"°C\", na=False)\n",
    "    df['is_degrees_celsius'] = df['is_degrees_celsius'].astype(int)\n",
    "    # x-y°C の形式になっている\n",
    "    df[\"min_temp\"] = -1\n",
    "    df[\"max_temp\"] = -1\n",
    "    for i, row in df.iterrows():\n",
    "        text = row[\"Caption\"]\n",
    "        assert isinstance(text, str)\n",
    "        if \"°C\" in text:\n",
    "            # x-y°C の形式になっている\n",
    "            match = re.search(r'(\\d+)-(\\d+)°C', text)\n",
    "            if match:\n",
    "                min_temp, max_temp = match.groups()\n",
    "                df.at[i, \"min_temp\"] = int(min_temp)\n",
    "                df.at[i, \"max_temp\"] = int(max_temp)\n",
    "            \n",
    "            # x°C と y°C の形式になっている\n",
    "            match = re.findall(r'(\\d+)°C', text)\n",
    "            if match:\n",
    "                temp_list = [int(t) for t in match]\n",
    "                df.at[i, \"min_temp\"] = min(temp_list)\n",
    "                df.at[i, \"max_temp\"] = max(temp_list)\n",
    "            \n",
    "        if \"°F\" in text:    \n",
    "            # x-y°F の形式になっている\n",
    "            match = re.search(r'(\\d+)-(\\d+)°F', text)\n",
    "            if match:\n",
    "                min_temp, max_temp = match.groups()\n",
    "                df.at[i, \"min_temp\"] = int(min_temp)\n",
    "                df.at[i, \"max_temp\"] = int(max_temp)\n",
    "                \n",
    "            # x°F と y°F の形式になっている\n",
    "            match = re.findall(r'(\\d+)°F', text)\n",
    "            if match:\n",
    "                temp_list = [int(t) for t in match]\n",
    "                df.at[i, \"min_temp\"] = min(temp_list)\n",
    "                df.at[i, \"max_temp\"] = max(temp_list)\n",
    "                \n",
    "            # Convert Fahrenheit to Celsius\n",
    "            if df.at[i, \"min_temp\"] != -1:\n",
    "                df.at[i, \"min_temp\"] = (df.at[i, \"min_temp\"] - 32) * 5 / 9\n",
    "            if df.at[i, \"max_temp\"] != -1:\n",
    "                df.at[i, \"max_temp\"] = (df.at[i, \"max_temp\"] - 32) * 5 / 9\n",
    "        \n",
    "    df[\"dff_tmp\"] = df[\"max_temp\"] - df[\"min_temp\"]\n",
    "    return df\n",
    "                \n",
    "\n",
    "# %%\n",
    "\n",
    "class joai_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, embedding, attention_mask, target_class,transform=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.embedding = embedding\n",
    "        self.attention_mask = attention_mask\n",
    "        self.target_class = target_class\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rgb_img_path = os.path.join(config.data_dir, \"images\", self.df.iloc[idx]['image_path_uuid'])\n",
    "        gray_img_path = os.path.join(config.data_dir, \"images_reverse\", self.df.iloc[idx]['image_path_uuid'].replace(\"RGB\", \"Gray\"))\n",
    "        # それぞれつなげて 4ch にする\n",
    "        rgb_img = Image.open(rgb_img_path).convert(\"RGB\")\n",
    "        gray_img = Image.open(gray_img_path).convert(\"L\")\n",
    "        gray_img = gray_img.resize((config.train_img_size, config.train_img_size))\n",
    "        gray_img = np.array(gray_img)\n",
    "        image = np.concatenate([np.array(rgb_img), gray_img[:, :, np.newaxis]], axis=2)\n",
    "                    \n",
    "        if self.transform:\n",
    "            if self.is_test is False and np.random.rand() < 0.5:\n",
    "                # 先に gridmask を行う\n",
    "                gridmask = GridMask(p=0.5, num_grid=5)\n",
    "                params = gridmask.get_params_dependent_on_targets({'image': image})\n",
    "                image = gridmask.apply(image.copy(), **params)\n",
    "            image = self.transform(image=image)['image']\n",
    "        \n",
    "        num_feature_list = []\n",
    "        for col in [\"MQ8\", \"MQ5\", \"is_degrees_celsius\", \"min_temp\", \"max_temp\", \"dff_tmp\"]:\n",
    "            num_feature_list.append(float(self.df.iloc[idx][col]))\n",
    "            \n",
    "        num_feature = np.array(num_feature_list, dtype=np.float32)\n",
    "        num_feature = torch.tensor(num_feature, dtype=torch.float32)\n",
    "        \n",
    "        embedding = torch.tensor(self.embedding[idx], dtype=torch.float32)\n",
    "        attention_mask = torch.tensor(self.attention_mask[idx], dtype=torch.float32)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return image, num_feature, embedding, attention_mask, -1\n",
    "        \n",
    "        else :\n",
    "            label = self.df.iloc[idx][\"Gas\"] == self.target_class\n",
    "            label = torch.tensor(label, dtype=torch.float32)\n",
    "            # soft labe にする\n",
    "            label = label * (1 - config.smoothing) + (1 - label) * config.smoothing\n",
    "            return image, num_feature, embedding, attention_mask, label\n",
    "\n",
    "# %%\n",
    "name_to_label = {\n",
    "    \"Mixture\": 0,\n",
    "    \"NoGas\": 1,\n",
    "    \"Perfume\": 2,\n",
    "    \"Smoke\": 3\n",
    "}\n",
    "\n",
    "# %%\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x.clamp(min=self.eps).pow(self.p), (x.size(-2), x.size(-1))).pow(1./self.p)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "# %%\n",
    "class joaiModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, numerical_feature_count=2):\n",
    "        super(joaiModel, self).__init__()\n",
    "        \n",
    "        # 画像部分 \n",
    "        self.model = timm.create_model(model_name, pretrained=True, num_classes=0, in_chans=4)\n",
    "        self.dropout = nn.Dropout(config.dropout_ratio)\n",
    "        self.fc_img = nn.Linear(self.model.num_features, 256)\n",
    "        \n",
    "        # 数値部分\n",
    "        self.fc_num = nn.Linear(numerical_feature_count, 128)\n",
    "        \n",
    "        # テキスト部分\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc_text = nn.Linear(768, 256)\n",
    "        \n",
    "        self.film_generator = nn.Sequential(\n",
    "            nn.Linear(128+256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256*2),\n",
    "        )\n",
    "        \n",
    "        self.fc_final = nn.Linear(256+256+128, 1)\n",
    "        \n",
    "    def forward(self, x, numerical_features, embedding, attention_mask):\n",
    "        x = self.model(x)\n",
    "        x = self.fc_img(x)\n",
    "        \n",
    "        numerical_features = self.fc_num(numerical_features)\n",
    "        numerical_features = F.relu(numerical_features)\n",
    "        \n",
    "        embedding = embedding.transpose(1, 2)\n",
    "        embedding = self.max_pool(embedding)\n",
    "        embedding = embedding.squeeze(-1)\n",
    "        embedding = self.fc_text(embedding)\n",
    "        embedding = F.relu(embedding)\n",
    "        \n",
    "        film_input = torch.cat([embedding, numerical_features], dim=1)\n",
    "        film_params = self.film_generator(film_input)\n",
    "        gamma, beta = torch.chunk(film_params, 2, dim=1)\n",
    "        \n",
    "        image_features = x * (1 + gamma) + beta\n",
    "        image_features = F.relu(image_features)\n",
    "        \n",
    "        combined_features = torch.cat([image_features, embedding, numerical_features], dim=1)\n",
    "        combined_features = self.fc_final(combined_features)\n",
    "        return combined_features\n",
    "        \n",
    "\n",
    "# %%\n",
    "class joai_pl_model(pl.LightningModule):\n",
    "    def __init__(self, model, len_train_loader):\n",
    "        super(joai_pl_model, self).__init__()\n",
    "        self.model = model\n",
    "        self.criterion = config.criterion()\n",
    "        self.do_wandb = config.do_wandb\n",
    "        self.len_train_loader = len_train_loader\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, numerical_features, embedding, attention_mask, labels = batch\n",
    "        outputs = self.model(images, numerical_features, embedding, attention_mask)\n",
    "        # 二値分類なのでoutputsは[batch_size, 1]の形状\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"lr\", self.trainer.optimizers[0].param_groups[0][\"lr\"], prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, numerical_features, embedding, attention_mask, labels = batch\n",
    "        if config.do_tta:\n",
    "            image_0 = images.clone()\n",
    "            image_1 = torch.flip(image_0, dims=[-1])\n",
    "            image_2 = torch.flip(image_0, dims=[-2])\n",
    "            image_3 = torch.flip(image_0, dims=[-1, -2])\n",
    "            output_0 = self.model(image_0, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            output_1 = self.model(image_1, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            output_2 = self.model(image_2, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            output_3 = self.model(image_3, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            outputs = (output_0 + output_1 + output_2 + output_3) / 4\n",
    "        else: \n",
    "            outputs = self.model(images, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            \n",
    "        loss = self.criterion(outputs, labels)\n",
    "        # 確率に変換して閾値0.5で二値化\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).float()\n",
    "        hard_labels = (labels > 0.5).float()    \n",
    "        \n",
    "        # 二値分類用の評価指標\n",
    "        val_f1 = f1_score(hard_labels.cpu().numpy(), preds.cpu().numpy(), average='binary')\n",
    "        val_precision = precision_score(hard_labels.cpu().numpy(), preds.cpu().numpy(), average='binary')\n",
    "        val_recall = recall_score(hard_labels.cpu().numpy(), preds.cpu().numpy(), average='binary')\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log('val_f1', torch.tensor(val_f1, device=self.device), prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log('val_precision', torch.tensor(val_precision, device=self.device), prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log('val_recall', torch.tensor(val_recall, device=self.device), prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"preds\": preds,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        images, numerical_features, embedding, attention_mask, labels = batch\n",
    "        if config.do_tta:\n",
    "            image_0 = images.clone()\n",
    "            image_1 = torch.flip(image_0, dims=[-1])\n",
    "            image_2 = torch.flip(image_0, dims=[-2])\n",
    "            image_3 = torch.flip(image_0, dims=[-1, -2])\n",
    "            output_0 = self.model(image_0, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            output_1 = self.model(image_1, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            output_2 = self.model(image_2, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            output_3 = self.model(image_3, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            outputs = (output_0 + output_1 + output_2 + output_3) / 4\n",
    "        else: \n",
    "            outputs = self.model(images, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            \n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).float()\n",
    "        return {\"probs\": probs, \"preds\": preds}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_for_pl = torch.optim.AdamW(self.parameters(), lr=config.learning_rate)\n",
    "        \n",
    "        # Calculate total training steps and warmup steps\n",
    "        num_training_steps = self.len_train_loader * config.epochs \n",
    "        num_warmup_steps = int(config.warmup_prop * num_training_steps)  # 10% of total steps for warmup\n",
    "        scueduler_obj = transformers.get_cosine_schedule_with_warmup(\n",
    "                optimizer_for_pl,\n",
    "                num_warmup_steps=num_warmup_steps,\n",
    "                num_training_steps=num_training_steps\n",
    "        )\n",
    "        # Create scheduler with proper parameters\n",
    "        scheduler = {\n",
    "            \"scheduler\": scueduler_obj,\n",
    "            \"interval\": \"step\",\n",
    "            \"frequency\": 1\n",
    "        }\n",
    "        return [optimizer_for_pl], [scheduler]\n",
    "\n",
    "# %%\n",
    "def run_train_cv_pl(train, test):    \n",
    "    train = add_degrees_celcius(train)\n",
    "    test = add_degrees_celcius(test)\n",
    "    train_embedding = np.load(\"/kaggle/input/joai-dataset/deberta_embeddings_train.npy\")\n",
    "    test_embedding = np.load(\"/kaggle/input/joai-dataset/deberta_embeddings_test.npy\")\n",
    "    train_attention_mask = np.load(\"/kaggle/input/joai-dataset/deberta_attention_masks_train.npy\")\n",
    "    test_attention_mask = np.load(\"/kaggle/input/joai-dataset/deberta_attention_masks_test.npy\")\n",
    "        \n",
    "    train_pred = pd.DataFrame(None, index=train.index, columns=name_to_label.keys())\n",
    "    test_pred = pd.DataFrame(None, index=test.index, columns=name_to_label.keys())\n",
    "    train_pred[list(name_to_label.keys())] = 0\n",
    "    test_pred[list(name_to_label.keys())] = 0\n",
    "    \n",
    "    for fold in range(config.fold):\n",
    "        print(f\"==========================fold {fold+1}==========================\")\n",
    "        if config.debug_one_fold and fold != 0:\n",
    "            break\n",
    "        print(f\"Fold {fold+1} / {config.fold}\")\n",
    "        seed_everything(config.random_seed)\n",
    "        \n",
    "        train_df = train[train['fold'] != fold].reset_index(drop=True)\n",
    "        val_df = train[train['fold'] == fold].reset_index(drop=True)\n",
    "        test_df = test.copy()\n",
    "        val_indices = train[train['fold'] == fold].index.tolist()\n",
    "        processor = QuantileTransformer(\n",
    "            n_quantiles=max(min(len(train_df)//10, 1000), 10),\n",
    "            output_distribution=\"normal\",\n",
    "            subsample=int(1e9),\n",
    "            random_state=config.random_seed\n",
    "        )\n",
    "        to_process = [\"MQ8\", \"MQ5\", \"max_temp\", \"min_temp\", \"dff_tmp\"]\n",
    "        for col in to_process:\n",
    "            train_df[col] = processor.fit_transform(train_df[[col]])\n",
    "            val_df[col] = processor.transform(val_df[[col]])\n",
    "            test_df[col] = processor.transform(test_df[[col]])\n",
    "        \n",
    "        train_tmp_embedding = train_embedding[train[train['fold'] != fold].index]\n",
    "        val_tmp_embedding = train_embedding[train[train['fold'] == fold].index]\n",
    "        train_tmp_attention_mask = train_attention_mask[train[train['fold'] != fold].index]\n",
    "        val_tmp_attention_mask = train_attention_mask[train[train['fold'] == fold].index]\n",
    "        \n",
    "        for label_name in name_to_label.keys():\n",
    "            train_dataset = joai_dataset(train_df, transform=train_transform, embedding=train_tmp_embedding, attention_mask=train_tmp_attention_mask, target_class=label_name)\n",
    "            val_dataset = joai_dataset(val_df, transform=test_transform, embedding=val_tmp_embedding, attention_mask=val_tmp_attention_mask, target_class=label_name)\n",
    "            test_dataset = joai_dataset(test_df, transform=test_transform, embedding=test_embedding, attention_mask=test_attention_mask, target_class=label_name, is_test=True)\n",
    "            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "            val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "            len_train_loader = len(train_loader)    \n",
    "            model = joaiModel(config.model, config.num_classes, numerical_feature_count=6)\n",
    "            pl_model = joai_pl_model(model, len_train_loader)\n",
    "        \n",
    "        \n",
    "            wandb_logger = None\n",
    "            if config.do_wandb:\n",
    "                wandb_logger = WandbLogger(\n",
    "                    project=\"JOAI\", \n",
    "                    group=config.exp_name, \n",
    "                    name=f\"fold{fold}_{label_name}\", \n",
    "                    config=class_dict, save_dir=\"logs\"\n",
    "                    )\n",
    "                # wandb に画像を保存\n",
    "                # 最初のバッチを保存\n",
    "                first_batch = next(iter(train_loader))\n",
    "                for i, image in enumerate(first_batch[0]):\n",
    "                    wandb_logger.log_image(\n",
    "                        key=f\"train_image_{i}\",\n",
    "                        images=[wandb.Image(image.permute(1, 2, 0).cpu().numpy())],\n",
    "                        caption=[f\"train_image_{i}\"]\n",
    "                    )\n",
    "                    if i== 16:\n",
    "                        break\n",
    "            \n",
    "            tensorboard_logger = TensorBoardLogger(\"logs\", name=f\"{config.exp_name}_fold{fold}\")\n",
    "        \n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                monitor='val_f1',\n",
    "                dirpath=os.path.join(config.output_dir, f\"{config.exp_name}_fold{fold}_{label_name}\"),\n",
    "                filename='best-checkpoint',\n",
    "                save_top_k=1,\n",
    "                mode='max'\n",
    "            )\n",
    "\n",
    "            early_stopping_callback = EarlyStopping(\n",
    "                monitor='val_f1',\n",
    "                patience=config.patience,\n",
    "                mode='max'\n",
    "            )\n",
    "\n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=config.epochs,\n",
    "                accelerator=\"gpu\",\n",
    "                devices=1,\n",
    "                logger=wandb_logger if config.do_wandb else tensorboard_logger,\n",
    "                callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                precision=config.precision,\n",
    "                log_every_n_steps=10,\n",
    "            )\n",
    "        \n",
    "            trainer.fit(pl_model, train_loader, val_loader)\n",
    "            best_model_path = checkpoint_callback.best_model_path\n",
    "            best_pl_model = joai_pl_model.load_from_checkpoint(\n",
    "                best_model_path,\n",
    "                model=model,\n",
    "                len_train_loader=len_train_loader\n",
    "            )\n",
    "        \n",
    "        \n",
    "            val_preds_list = trainer.predict(best_pl_model, val_loader)\n",
    "            val_probs = np.concatenate([x['probs'].cpu().numpy() for x in val_preds_list], axis=0)\n",
    "            train_pred.loc[val_indices, label_name] += val_probs\n",
    "            \n",
    "            test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "            test_preds_list = trainer.predict(best_pl_model, test_loader)\n",
    "            test_probs = np.concatenate([x['probs'].cpu().numpy() for x in test_preds_list], axis=0)\n",
    "            test_pred.loc[:, label_name] += test_probs\n",
    "            del model, trainer, train_loader, val_loader, test_loader, best_pl_model, best_model_path\n",
    "            if config.do_wandb:\n",
    "                wandb.finish()\n",
    "                del wandb_logger\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        if config.debug_one_fold:\n",
    "            break\n",
    "        \n",
    "    return {\n",
    "        \"oof\": train_pred.values,\n",
    "        \"predictions\": test_pred.values\n",
    "    }\n",
    "\n",
    "# %%\n",
    "def main():\n",
    "    if config.only_infer:\n",
    "        raise ValueError(\"Inference mode is not implemented yet.\")\n",
    "    else:\n",
    "        train = pd.read_csv(os.path.join(config.data_dir, \"train_folds.csv\"))\n",
    "        test = pd.read_csv(os.path.join(config.data_dir, \"test.csv\"))\n",
    "        name_to_label = {\n",
    "            \"Mixture\": 0,\n",
    "            \"NoGas\": 1,\n",
    "            \"Perfume\": 2,\n",
    "            \"Smoke\": 3\n",
    "        }\n",
    "        label_to_name = {v: k for k, v in name_to_label.items()}\n",
    "        pred_dict = run_train_cv_pl(train, test)\n",
    "        oof_preds = pred_dict[\"oof\"]\n",
    "        # 後処理として、 oof_preds の is_degrees_celsius が 1 だった場合に Perfume と Smoke のラベル以外の確率を 0 にする\n",
    "        train_tmp = add_degrees_celcius(train)\n",
    "        for i in range(len(oof_preds)):\n",
    "            if train_tmp.iloc[i][\"is_degrees_celsius\"] == 1 and \"°f\" not in train_tmp.iloc[i][\"Caption\"].lower():\n",
    "                oof_preds[i][0] = 0\n",
    "                oof_preds[i][3] = 0\n",
    "                \n",
    "         \n",
    "        test_preds = pred_dict[\"predictions\"]\n",
    "        test_tmp = add_degrees_celcius(test)\n",
    "        for i in range(len(test_preds)):\n",
    "            if test_tmp.iloc[i][\"is_degrees_celsius\"] == 1 and np.argmax(test_preds[i]) not in [1, 2]:\n",
    "                print(\"there's a possibility of miss classification\")\n",
    "                print(i, test_preds[i])\n",
    "            # Checking if it's in Celsius and doesn't contain Fahrenheit\n",
    "            if test_tmp.iloc[i][\"is_degrees_celsius\"] == 1 and \"°f\" not in test_tmp.iloc[i][\"Caption\"].lower():\n",
    "                test_preds[i][0] = 0\n",
    "                test_preds[i][3] = 0\n",
    "            \n",
    "        print(\"oof_preds shape:\", oof_preds.shape)\n",
    "        print(\"test_preds shape:\", test_preds.shape)\n",
    "        \n",
    "        for i, class_name in enumerate(label_to_name.values()):\n",
    "            print(f\"{class_name}: {i}\")\n",
    "            train[class_name] = oof_preds[:, i]*5\n",
    "            \n",
    "        train.to_csv(os.path.join(config.output_dir, f\"{config.exp_name}_oof.csv\"), index=False)\n",
    "        \n",
    "        for i, class_name in enumerate(label_to_name.values()):\n",
    "            test[class_name] = test_preds[:, i]\n",
    "            \n",
    "        test.to_csv(os.path.join(config.output_dir, f\"{config.exp_name}_test_probs.csv\"), index=False)\n",
    "        \n",
    "        # oof_preds は予測の確率が格納された配列\n",
    "        oof_preds = np.argmax(oof_preds, axis=1)\n",
    "        print(f\"valid_total_f1: {f1_score(train['Gas'].apply(lambda x: name_to_label[x]).values, oof_preds, average='weighted')}\")\n",
    "        test_preds = np.argmax(test_preds, axis=1)\n",
    "        sample_submission = pd.read_csv(os.path.join(config.data_dir, \"sample_submission.csv\"))\n",
    "        sample_submission['Gas'] = test_preds\n",
    "        sample_submission['Gas'] = sample_submission['Gas'].map(label_to_name)\n",
    "        sample_submission.to_csv(os.path.join(config.output_dir, f\"{config.exp_name}_submission.csv\"), index=False)\n",
    "        print(\"Inference completed. Submission file saved.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11435459,
     "sourceId": 96289,
     "sourceType": "competition"
    },
    {
     "datasetId": 7262737,
     "sourceId": 11626692,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
