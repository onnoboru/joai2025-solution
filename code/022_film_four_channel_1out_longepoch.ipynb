{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5eb0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/usr/local/cuda\"\n",
    "# または環境変数を完全に無効化\n",
    "os.environ[\"PJRT_DEVICE\"] = \"CUDA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1347eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noboru/.local/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: '2.0.6' (you have '2.0.0'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "2025-04-30 21:54:02.662688: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-30 21:54:03.313099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746017643.514214 1309197 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746017643.570770 1309197 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746017644.035702 1309197 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746017644.035850 1309197 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746017644.035855 1309197 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746017644.035859 1309197 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-30 21:54:04.108858: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-30 21:54:12 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import copy\n",
    "import random\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import seed_everything as pl_seed_everything\n",
    "from lightning.pytorch.loggers import WandbLogger, TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "import transformers\n",
    "\n",
    "import wandb\n",
    "\n",
    "from albumentations.core.transforms_interface import DualTransform\n",
    "from albumentations.augmentations import functional as AF\n",
    "\n",
    "# from joai_toolkit.src.cv import image_augumentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5b24ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG : \n",
    "    exp_name = \"021_film_four_channel_1out\"\n",
    "    random_seed = 42\n",
    "    \n",
    "    # model info\n",
    "    model = \"resnet50.a1h_in1k\"\n",
    "    use_custom_pooling = False\n",
    "    dropout_ratio = 0.3\n",
    "    \n",
    "    # train info\n",
    "    epochs = 100\n",
    "    batch_size = 64\n",
    "    learning_rate = 1e-3\n",
    "    num_workers = 8\n",
    "    num_classes = 4\n",
    "    device = \"cuda\"\n",
    "    criterion =  nn.BCEWithLogitsLoss\n",
    "    optimizer = optim.AdamW \n",
    "    scheduler = transformers.get_cosine_schedule_with_warmup\n",
    "    warmup_prop = 0.1\n",
    "    patience = 10\n",
    "    precision = \"16-mixed\" \n",
    "    do_tta = False\n",
    "    smoothing = 0.01\n",
    "    \n",
    "    # run info\n",
    "    debug_one_epoch = False\n",
    "    debug_one_fold = False\n",
    "    only_infer = False\n",
    "    do_wandb = True\n",
    "    \n",
    "    # data info\n",
    "    imput_img_size = 224\n",
    "    train_img_size = 224\n",
    "    data_dir = \"../dataset\"\n",
    "    output_dir = \"../outputs\"\n",
    "    fold = 5\n",
    "    \n",
    "config = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5e0261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    pl_seed_everything(seed)\n",
    "    \n",
    "seed_everything(config.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf3ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_to_dict(obj):\n",
    "    return {k: getattr(obj, k) for k in dir(obj) if not k.startswith(\"__\") and not callable(getattr(obj, k))}\n",
    "class_dict = class_to_dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridMask(DualTransform):\n",
    "    \"\"\"GridMask augmentation for image classification and object detection.\n",
    "\n",
    "    Citation : This code is copied from and based on the original code from https://www.kaggle.com/code/haqishen/gridmask\n",
    "    Thanks to the author.\n",
    "    \n",
    "    Args:\n",
    "        num_grid (int): number of grid in a row or column.\n",
    "        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\n",
    "        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\n",
    "            an angle is picked from (-rotate, rotate). Default: (-90, 90)\n",
    "        mode (int):\n",
    "            0 - cropout a quarter of the square of each grid (left top)\n",
    "            1 - reserve a quarter of the square of each grid (left top)\n",
    "            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\n",
    "\n",
    "    Targets:\n",
    "        image, mask\n",
    "\n",
    "    Image types:\n",
    "        uint8, float32\n",
    "\n",
    "    Reference:\n",
    "    |  https://arxiv.org/abs/2001.04086\n",
    "    |  https://github.com/akuxcw/GridMask\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
    "        super(GridMask, self).__init__(always_apply, p)\n",
    "        if isinstance(num_grid, int):\n",
    "            num_grid = (num_grid, num_grid)\n",
    "        if isinstance(rotate, int):\n",
    "            rotate = (-rotate, rotate)\n",
    "        self.num_grid = num_grid\n",
    "        self.fill_value = fill_value\n",
    "        self.rotate = rotate\n",
    "        self.mode = mode\n",
    "        self.masks = None\n",
    "        self.rand_h_max = []\n",
    "        self.rand_w_max = []\n",
    "\n",
    "    def init_masks(self, height, width):\n",
    "        if self.masks is None:\n",
    "            self.masks = []\n",
    "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
    "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
    "                grid_h = height / n_g\n",
    "                grid_w = width / n_g\n",
    "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
    "                for i in range(n_g + 1):\n",
    "                    for j in range(n_g + 1):\n",
    "                        this_mask[\n",
    "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
    "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
    "                        ] = self.fill_value\n",
    "                        if self.mode == 2:\n",
    "                            this_mask[\n",
    "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
    "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
    "                            ] = self.fill_value\n",
    "                \n",
    "                if self.mode == 1:\n",
    "                    this_mask = 1 - this_mask\n",
    "\n",
    "                self.masks.append(this_mask)\n",
    "                self.rand_h_max.append(grid_h)\n",
    "                self.rand_w_max.append(grid_w)\n",
    "                \n",
    "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
    "        h, w = image.shape[:2]\n",
    "        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
    "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
    "        # 新しい配列を作成して返す\n",
    "        new_image = image.copy()  # 画像のコピーを作成\n",
    "        new_image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
    "        return new_image\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        img = params['image']\n",
    "        height, width = img.shape[:2]\n",
    "        self.init_masks(height, width)\n",
    "\n",
    "        mid = np.random.randint(len(self.masks))\n",
    "        mask = self.masks[mid]\n",
    "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
    "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
    "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
    "\n",
    "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
    "\n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('num_grid', 'fill_value', 'rotate', 'mode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "148cacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(config.train_img_size, config.train_img_size),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(config.imput_img_size, config.imput_img_size),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43ae42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_degrees_celcius(df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add a column to the DataFrame indicating if the temperature is in Celsius.\n",
    "    \"\"\"\n",
    "    df[\"Caption\"] = df[\"Caption\"].astype(str) \n",
    "    df['is_degrees_celsius'] = df[\"Caption\"].str.contains(\"°C\", na=False)\n",
    "    df['is_degrees_celsius'] = df['is_degrees_celsius'].astype(int)\n",
    "    # x-y°C の形式になっている\n",
    "    df[\"min_temp\"] = -1\n",
    "    df[\"max_temp\"] = -1\n",
    "    for i, row in df.iterrows():\n",
    "        text = row[\"Caption\"]\n",
    "        assert isinstance(text, str)\n",
    "        if \"°C\" in text:\n",
    "            # x-y°C の形式になっている\n",
    "            match = re.search(r'(\\d+)-(\\d+)°C', text)\n",
    "            if match:\n",
    "                min_temp, max_temp = match.groups()\n",
    "                df.at[i, \"min_temp\"] = int(min_temp)\n",
    "                df.at[i, \"max_temp\"] = int(max_temp)\n",
    "            \n",
    "            # x°C と y°C の形式になっている\n",
    "            match = re.findall(r'(\\d+)°C', text)\n",
    "            if match:\n",
    "                temp_list = [int(t) for t in match]\n",
    "                df.at[i, \"min_temp\"] = min(temp_list)\n",
    "                df.at[i, \"max_temp\"] = max(temp_list)\n",
    "            \n",
    "        if \"°F\" in text:    \n",
    "            # x-y°F の形式になっている\n",
    "            match = re.search(r'(\\d+)-(\\d+)°F', text)\n",
    "            if match:\n",
    "                min_temp, max_temp = match.groups()\n",
    "                df.at[i, \"min_temp\"] = int(min_temp)\n",
    "                df.at[i, \"max_temp\"] = int(max_temp)\n",
    "                \n",
    "            # x°F と y°F の形式になっている\n",
    "            match = re.findall(r'(\\d+)°F', text)\n",
    "            if match:\n",
    "                temp_list = [int(t) for t in match]\n",
    "                df.at[i, \"min_temp\"] = min(temp_list)\n",
    "                df.at[i, \"max_temp\"] = max(temp_list)\n",
    "                \n",
    "            # Convert Fahrenheit to Celsius\n",
    "            if df.at[i, \"min_temp\"] != -1:\n",
    "                df.at[i, \"min_temp\"] = (df.at[i, \"min_temp\"] - 32) * 5 / 9\n",
    "            if df.at[i, \"max_temp\"] != -1:\n",
    "                df.at[i, \"max_temp\"] = (df.at[i, \"max_temp\"] - 32) * 5 / 9\n",
    "        \n",
    "    df[\"dff_tmp\"] = df[\"max_temp\"] - df[\"min_temp\"]\n",
    "    return df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf42599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class joai_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, embedding, attention_mask, target_class,transform=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.embedding = embedding\n",
    "        self.attention_mask = attention_mask\n",
    "        self.target_class = target_class\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rgb_img_path = os.path.join(config.data_dir, \"images\", self.df.iloc[idx]['image_path_uuid'])\n",
    "        gray_img_path = os.path.join(config.data_dir, \"images_reverse\", self.df.iloc[idx]['image_path_uuid'].replace(\"RGB\", \"Gray\"))\n",
    "        # それぞれつなげて 4ch にする\n",
    "        rgb_img = Image.open(rgb_img_path).convert(\"RGB\")\n",
    "        gray_img = Image.open(gray_img_path).convert(\"L\")\n",
    "        gray_img = gray_img.resize((config.train_img_size, config.train_img_size))\n",
    "        gray_img = np.array(gray_img)\n",
    "        image = np.concatenate([np.array(rgb_img), gray_img[:, :, np.newaxis]], axis=2)\n",
    "                    \n",
    "        if self.transform:\n",
    "            if self.is_test is False and np.random.rand() < 0.5:\n",
    "                # 先に gridmask を行う\n",
    "                # gridmask = image_augumentation.GridMask(p=0.5, num_grid=5) # 変更前\n",
    "                gridmask = GridMask(p=0.5, num_grid=5) # 変更後\n",
    "                params = gridmask.get_params_dependent_on_targets({'image': image})\n",
    "                image = gridmask.apply(image.copy(), **params)\n",
    "            image = self.transform(image=image)['image']\n",
    "        \n",
    "        num_feature_list = []\n",
    "        for col in [\"MQ8\", \"MQ5\", \"is_degrees_celsius\", \"min_temp\", \"max_temp\", \"dff_tmp\"]:\n",
    "            num_feature_list.append(float(self.df.iloc[idx][col]))\n",
    "            \n",
    "        num_feature = np.array(num_feature_list, dtype=np.float32)\n",
    "        num_feature = torch.tensor(num_feature, dtype=torch.float32)\n",
    "        \n",
    "        embedding = torch.tensor(self.embedding[idx], dtype=torch.float32)\n",
    "        attention_mask = torch.tensor(self.attention_mask[idx], dtype=torch.float32)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return image, num_feature, embedding, attention_mask, -1\n",
    "        \n",
    "        else :\n",
    "            label = self.df.iloc[idx][\"Gas\"] == self.target_class\n",
    "            label = torch.tensor(label, dtype=torch.float32)\n",
    "            # soft labe にする\n",
    "            label = label * (1 - config.smoothing) + (1 - label) * config.smoothing\n",
    "            return image, num_feature, embedding, attention_mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e87918a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_label = {\n",
    "    \"Mixture\": 0,\n",
    "    \"NoGas\": 1,\n",
    "    \"Perfume\": 2,\n",
    "    \"Smoke\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3d9e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x.clamp(min=self.eps).pow(self.p), (x.size(-2), x.size(-1))).pow(1./self.p)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f7a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class joaiModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, numerical_feature_count=2):\n",
    "        super(joaiModel, self).__init__()\n",
    "        \n",
    "        # 画像部分 \n",
    "        self.model = timm.create_model(model_name, pretrained=True, num_classes=0, in_chans=4)\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.gem = GeM()\n",
    "        self.dropout = nn.Dropout(config.dropout_ratio)\n",
    "        self.fc_img = nn.Linear(self.model.num_features, 256)\n",
    "        \n",
    "        # 数値部分\n",
    "        self.fc_num = nn.Linear(numerical_feature_count, 128)\n",
    "        \n",
    "        # テキスト部分\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc_text = nn.Linear(768, 256)\n",
    "        \n",
    "        self.film_generator = nn.Sequential(\n",
    "            nn.Linear(128+256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256*2),\n",
    "        )\n",
    "        \n",
    "        self.fc_final = nn.Linear(256+256+128, 1)\n",
    "        \n",
    "    def forward(self, x, numerical_features, embedding, attention_mask):\n",
    "        x = self.model(x)\n",
    "        x = self.gem(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_img(x)\n",
    "        \n",
    "        numerical_features = self.fc_num(numerical_features)\n",
    "        numerical_features = F.relu(numerical_features)\n",
    "        \n",
    "        embedding = embedding.transpose(1, 2)\n",
    "        embedding = self.max_pool(embedding)\n",
    "        embedding = embedding.squeeze(-1)\n",
    "        embedding = self.fc_text(embedding)\n",
    "        embedding = F.relu(embedding)\n",
    "        \n",
    "        film_input = torch.cat([embedding, numerical_features], dim=1)\n",
    "        film_params = self.film_generator(film_input)\n",
    "        gamma, beta = torch.chunk(film_params, 2, dim=1)\n",
    "        \n",
    "        image_features = x * (1 + gamma) + beta\n",
    "        image_features = F.relu(image_features)\n",
    "        \n",
    "        combined_features = torch.cat([image_features, embedding, numerical_features], dim=1)\n",
    "        combined_features = self.fc_final(combined_features)\n",
    "        return combined_features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8061f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class joai_pl_model(pl.LightningModule):\n",
    "    def __init__(self, model, len_train_loader):\n",
    "        super(joai_pl_model, self).__init__()\n",
    "        self.model = model\n",
    "        self.criterion = config.criterion()\n",
    "        self.do_wandb = config.do_wandb\n",
    "        self.len_train_loader = len_train_loader\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, numerical_features, embedding, attention_mask, labels = batch\n",
    "        outputs = self.model(images, numerical_features, embedding, attention_mask)\n",
    "        # 二値分類なのでoutputsは[batch_size, 1]の形状\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"lr\", self.trainer.optimizers[0].param_groups[0][\"lr\"], prog_bar=True, on_step=True, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, numerical_features, embedding, attention_mask, labels = batch\n",
    "        if config.do_tta:\n",
    "            image_0 = images.clone()\n",
    "            image_1 = torch.flip(image_0, dims=[-1])\n",
    "            image_2 = torch.flip(image_0, dims=[-2])\n",
    "            image_3 = torch.flip(image_0, dims=[-1, -2])\n",
    "            output_0 = self.model(image_0, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            output_1 = self.model(image_1, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            output_2 = self.model(image_2, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            output_3 = self.model(image_3, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            outputs = (output_0 + output_1 + output_2 + output_3) / 4\n",
    "        else: \n",
    "            outputs = self.model(images, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            \n",
    "        loss = self.criterion(outputs, labels)\n",
    "        # 確率に変換して閾値0.5で二値化\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).float()\n",
    "        hard_labels = (labels > 0.5).float()    \n",
    "        \n",
    "        # 二値分類用の評価指標\n",
    "        val_f1 = f1_score(hard_labels.cpu().numpy(), preds.cpu().numpy(), average='binary')\n",
    "        val_precision = precision_score(hard_labels.cpu().numpy(), preds.cpu().numpy(), average='binary')\n",
    "        val_recall = recall_score(hard_labels.cpu().numpy(), preds.cpu().numpy(), average='binary')\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log('val_f1', torch.tensor(val_f1, device=self.device), prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log('val_precision', torch.tensor(val_precision, device=self.device), prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log('val_recall', torch.tensor(val_recall, device=self.device), prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"preds\": preds,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        images, numerical_features, embedding, attention_mask, labels = batch\n",
    "        if config.do_tta:\n",
    "            image_0 = images.clone()\n",
    "            image_1 = torch.flip(image_0, dims=[-1])\n",
    "            image_2 = torch.flip(image_0, dims=[-2])\n",
    "            image_3 = torch.flip(image_0, dims=[-1, -2])\n",
    "            output_0 = self.model(image_0, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            output_1 = self.model(image_1, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            output_2 = self.model(image_2, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            output_3 = self.model(image_3, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            outputs = (output_0 + output_1 + output_2 + output_3) / 4\n",
    "        else: \n",
    "            outputs = self.model(images, numerical_features, embedding, attention_mask).squeeze(-1)\n",
    "            \n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).float()\n",
    "        return {\"probs\": probs, \"preds\": preds}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_for_pl = torch.optim.AdamW(self.parameters(), lr=config.learning_rate)\n",
    "        \n",
    "        # Calculate total training steps and warmup steps\n",
    "        num_training_steps = self.len_train_loader * config.epochs \n",
    "        num_warmup_steps = int(config.warmup_prop * num_training_steps)  # 10% of total steps for warmup\n",
    "        scueduler_obj = transformers.get_cosine_schedule_with_warmup(\n",
    "                optimizer_for_pl,\n",
    "                num_warmup_steps=num_warmup_steps,\n",
    "                num_training_steps=num_training_steps\n",
    "        )\n",
    "        # Create scheduler with proper parameters\n",
    "        scheduler = {\n",
    "            \"scheduler\": scueduler_obj,\n",
    "            \"interval\": \"step\",\n",
    "            \"frequency\": 1\n",
    "        }\n",
    "        return [optimizer_for_pl], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0832925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_cv_pl(train, test):    \n",
    "    train = add_degrees_celcius(train)\n",
    "    test = add_degrees_celcius(test)\n",
    "    train_embedding = np.load(\"../dataset/deberta_embeddings_train.npy\")\n",
    "    test_embedding = np.load(\"../dataset/deberta_embeddings_test.npy\")\n",
    "    train_attention_mask = np.load(\"../dataset/deberta_attention_masks_train.npy\")\n",
    "    test_attention_mask = np.load(\"../dataset/deberta_attention_masks_test.npy\")\n",
    "        \n",
    "    train_pred = pd.DataFrame(None, index=train.index, columns=name_to_label.keys())\n",
    "    test_pred = pd.DataFrame(None, index=test.index, columns=name_to_label.keys())\n",
    "    train_pred[list(name_to_label.keys())] = 0\n",
    "    test_pred[list(name_to_label.keys())] = 0\n",
    "    \n",
    "    for fold in range(config.fold):\n",
    "        print(f\"==========================fold {fold+1}==========================\")\n",
    "        if config.debug_one_fold and fold != 0:\n",
    "            break\n",
    "        print(f\"Fold {fold+1} / {config.fold}\")\n",
    "        seed_everything(config.random_seed)\n",
    "        \n",
    "        train_df = train[train['fold'] != fold].reset_index(drop=True)\n",
    "        val_df = train[train['fold'] == fold].reset_index(drop=True)\n",
    "        test_df = test.copy()\n",
    "        val_indices = train[train['fold'] == fold].index.tolist()\n",
    "        processor = QuantileTransformer(\n",
    "            n_quantiles=max(min(len(train_df)//10, 1000), 10),\n",
    "            output_distribution=\"normal\",\n",
    "            subsample=int(1e9),\n",
    "            random_state=config.random_seed\n",
    "        )\n",
    "        to_process = [\"MQ8\", \"MQ5\", \"max_temp\", \"min_temp\", \"dff_tmp\"]\n",
    "        for col in to_process:\n",
    "            train_df[col] = processor.fit_transform(train_df[[col]])\n",
    "            val_df[col] = processor.transform(val_df[[col]])\n",
    "            test_df[col] = processor.transform(test_df[[col]])\n",
    "        \n",
    "        train_tmp_embedding = train_embedding[train[train['fold'] != fold].index]\n",
    "        val_tmp_embedding = train_embedding[train[train['fold'] == fold].index]\n",
    "        train_tmp_attention_mask = train_attention_mask[train[train['fold'] != fold].index]\n",
    "        val_tmp_attention_mask = train_attention_mask[train[train['fold'] == fold].index]\n",
    "        \n",
    "        for label_name in name_to_label.keys():\n",
    "            train_dataset = joai_dataset(train_df, transform=train_transform, embedding=train_tmp_embedding, attention_mask=train_tmp_attention_mask, target_class=label_name)\n",
    "            val_dataset = joai_dataset(val_df, transform=test_transform, embedding=val_tmp_embedding, attention_mask=val_tmp_attention_mask, target_class=label_name)\n",
    "            test_dataset = joai_dataset(test_df, transform=test_transform, embedding=test_embedding, attention_mask=test_attention_mask, target_class=label_name, is_test=True)\n",
    "            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "            val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "            len_train_loader = len(train_loader)    \n",
    "            model = joaiModel(config.model, config.num_classes, numerical_feature_count=6)\n",
    "            pl_model = joai_pl_model(model, len_train_loader)\n",
    "        \n",
    "        \n",
    "            wandb_logger = None\n",
    "            if config.do_wandb:\n",
    "                wandb_logger = WandbLogger(\n",
    "                    project=\"JOAI\", \n",
    "                    group=config.exp_name, \n",
    "                    name=f\"fold{fold}_{label_name}\", \n",
    "                    config=class_dict, save_dir=\"logs\"\n",
    "                    )\n",
    "                # wandb に画像を保存\n",
    "                # 最初のバッチを保存\n",
    "                first_batch = next(iter(train_loader))\n",
    "                for i, image in enumerate(first_batch[0]):\n",
    "                    wandb_logger.log_image(\n",
    "                        key=f\"train_image_{i}\",\n",
    "                        images=[wandb.Image(image.permute(1, 2, 0).cpu().numpy())],\n",
    "                        caption=[f\"train_image_{i}\"]\n",
    "                    )\n",
    "                    if i== 16:\n",
    "                        break\n",
    "            \n",
    "            tensorboard_logger = TensorBoardLogger(\"logs\", name=f\"{config.exp_name}_fold{fold}\")\n",
    "        \n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                monitor='val_f1',\n",
    "                dirpath=os.path.join(config.output_dir, f\"{config.exp_name}_fold{fold}_{label_name}\"),\n",
    "                filename='best-checkpoint',\n",
    "                save_top_k=1,\n",
    "                mode='max'\n",
    "            )\n",
    "\n",
    "            early_stopping_callback = EarlyStopping(\n",
    "                monitor='val_f1',\n",
    "                patience=config.patience,\n",
    "                mode='max'\n",
    "            )\n",
    "\n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=config.epochs,\n",
    "                accelerator=\"gpu\",\n",
    "                devices=1,\n",
    "                logger=wandb_logger if config.do_wandb else tensorboard_logger,\n",
    "                callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                precision=config.precision,\n",
    "                log_every_n_steps=10,\n",
    "            )\n",
    "        \n",
    "            trainer.fit(pl_model, train_loader, val_loader)\n",
    "            best_model_path = checkpoint_callback.best_model_path\n",
    "            best_pl_model = joai_pl_model.load_from_checkpoint(\n",
    "                best_model_path,\n",
    "                model=model,\n",
    "                len_train_loader=len_train_loader\n",
    "            )\n",
    "        \n",
    "        \n",
    "            val_preds_list = trainer.predict(best_pl_model, val_loader)\n",
    "            val_probs = np.concatenate([x['probs'].cpu().numpy() for x in val_preds_list], axis=0)\n",
    "            train_pred.loc[val_indices, label_name] += val_probs\n",
    "            \n",
    "            test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "            test_preds_list = trainer.predict(best_pl_model, test_loader)\n",
    "            test_probs = np.concatenate([x['probs'].cpu().numpy() for x in test_preds_list], axis=0)\n",
    "            test_pred.loc[:, label_name] += test_probs\n",
    "            del model, trainer, train_loader, val_loader, test_loader, best_pl_model, best_model_path\n",
    "            if config.do_wandb:\n",
    "                wandb.finish()\n",
    "                del wandb_logger\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        if config.debug_one_fold:\n",
    "            break\n",
    "        \n",
    "    return {\n",
    "        \"oof\": train_pred.values,\n",
    "        \"predictions\": test_pred.values\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25e044c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference completed. Submission file saved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m name_to_label \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixture\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNoGas\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerfume\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSmoke\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     13\u001b[0m label_to_name \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m name_to_label\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 14\u001b[0m pred_dict \u001b[38;5;241m=\u001b[39m \u001b[43mrun_train_cv_pl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m oof_preds \u001b[38;5;241m=\u001b[39m pred_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moof\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 後処理として、 oof_preds の is_degrees_celsius が 1 だった場合に Perfume と Smoke のラベル以外の確率を 0 にする\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m, in \u001b[0;36mrun_train_cv_pl\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m      2\u001b[0m train \u001b[38;5;241m=\u001b[39m add_degrees_celcius(train)\n\u001b[1;32m      3\u001b[0m test \u001b[38;5;241m=\u001b[39m add_degrees_celcius(test)\n\u001b[0;32m----> 4\u001b[0m train_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../dataset/deberta_embeddings_train.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m test_embedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataset/deberta_embeddings_test.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m train_attention_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataset/deberta_attention_masks_train.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:456\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    454\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/format.py:809\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    808\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    822\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if config.only_infer:\n",
    "        raise ValueError(\"Inference mode is not implemented yet.\")\n",
    "    else:\n",
    "        train = pd.read_csv(os.path.join(config.data_dir, \"train_folds.csv\"))\n",
    "        test = pd.read_csv(os.path.join(config.data_dir, \"test.csv\"))\n",
    "        name_to_label = {\n",
    "            \"Mixture\": 0,\n",
    "            \"NoGas\": 1,\n",
    "            \"Perfume\": 2,\n",
    "            \"Smoke\": 3\n",
    "        }\n",
    "        label_to_name = {v: k for k, v in name_to_label.items()}\n",
    "        pred_dict = run_train_cv_pl(train, test)\n",
    "        oof_preds = pred_dict[\"oof\"]\n",
    "        # 後処理として、 oof_preds の is_degrees_celsius が 1 だった場合に Perfume と Smoke のラベル以外の確率を 0 にする\n",
    "        train_tmp = add_degrees_celcius(train)\n",
    "        for i in range(len(oof_preds)):\n",
    "            if train_tmp.iloc[i][\"is_degrees_celsius\"] == 1 and \"°f\" not in train_tmp.iloc[i][\"Caption\"].lower():\n",
    "                oof_preds[i][0] = 0\n",
    "                oof_preds[i][3] = 0\n",
    "                \n",
    "         \n",
    "        test_preds = pred_dict[\"predictions\"]\n",
    "        test_tmp = add_degrees_celcius(test)\n",
    "        for i in range(len(test_preds)):\n",
    "            if test_tmp.iloc[i][\"is_degrees_celsius\"] == 1 and np.argmax(test_preds[i]) not in [1, 2]:\n",
    "                print(\"there's a possibility of miss classification\")\n",
    "                print(i, test_preds[i])\n",
    "            # Checking if it's in Celsius and doesn't contain Fahrenheit\n",
    "            if test_tmp.iloc[i][\"is_degrees_celsius\"] == 1 and \"°f\" not in test_tmp.iloc[i][\"Caption\"].lower():\n",
    "                test_preds[i][0] = 0\n",
    "                test_preds[i][3] = 0\n",
    "            \n",
    "        print(\"oof_preds shape:\", oof_preds.shape)\n",
    "        print(\"test_preds shape:\", test_preds.shape)\n",
    "        \n",
    "        for i, class_name in enumerate(label_to_name.values()):\n",
    "            print(f\"{class_name}: {i}\")\n",
    "            train[class_name] = oof_preds[:, i]\n",
    "            \n",
    "        train.to_csv(os.path.join(config.output_dir, f\"{config.exp_name}_oof.csv\"), index=False)\n",
    "        \n",
    "        for i, class_name in enumerate(label_to_name.values()):\n",
    "            test[class_name] = test_preds[:, i]\n",
    "            \n",
    "        test.to_csv(os.path.join(config.output_dir, f\"{config.exp_name}_test_probs.csv\"), index=False)\n",
    "        \n",
    "        # oof_preds は予測の確率が格納された配列\n",
    "        oof_preds = np.argmax(oof_preds, axis=1)\n",
    "        print(f\"valid_total_f1: {f1_score(train['Gas'].apply(lambda x: name_to_label[x]).values, oof_preds, average='weighted')}\")\n",
    "        test_preds = np.argmax(test_preds, axis=1)\n",
    "        sample_submission = pd.read_csv(os.path.join(config.data_dir, \"sample_submission.csv\"))\n",
    "        sample_submission['Gas'] = test_preds\n",
    "        sample_submission['Gas'] = sample_submission['Gas'].map(label_to_name)\n",
    "        sample_submission.to_csv(os.path.join(config.output_dir, f\"{config.exp_name}_submission.csv\"), index=False)\n",
    "        print(\"Inference completed. Submission file saved.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
